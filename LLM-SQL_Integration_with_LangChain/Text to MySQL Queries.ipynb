{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to MySQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'llama3.2:3b', 'created_at': '2025-02-01T07:17:21.7304908Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8880999000, 'load_duration': 7769770500, 'prompt_eval_count': 26, 'prompt_eval_duration': 824000000, 'eval_count': 8, 'eval_duration': 258000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f4cde6a5-223a-43bc-bff9-c43d6b236733-0', usage_metadata={'input_tokens': 26, 'output_tokens': 8, 'total_tokens': 34})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "llm = ChatOllama(model='llama3.2:3b', base_url='http://localhost:11434')\n",
    "llm.invoke('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in d:\\programs\\anaconda3\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"mysql+pymysql://root:amanah33@localhost/belajar_mysql\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'barang', 'categories', 'customer', 'guestbooks', 'orders', 'orders_detail', 'product', 'seller', 'wallet', 'wishlist']\n"
     ]
    }
   ],
   "source": [
    "name_all_tables = db.get_table_names()\n",
    "print(name_all_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE orders (\n",
      "\tid INTEGER NOT NULL AUTO_INCREMENT, \n",
      "\ttotal INTEGER NOT NULL, \n",
      "\torder_date DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, \n",
      "\tPRIMARY KEY (id)\n",
      ")COLLATE utf8mb4_0900_ai_ci ENGINE=InnoDB DEFAULT CHARSET=utf8mb4\n",
      "\n",
      "/*\n",
      "3 rows from orders table:\n",
      "id\ttotal\torder_date\n",
      "1\t50000\t2024-09-27 21:02:28\n",
      "2\t50000\t2024-09-27 21:08:55\n",
      "3\t50000\t2024-09-27 21:08:56\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan semua tabel dalam database\n",
    "tables = db.get_table_info(table_names=[\"orders\"])\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Query Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert the question into a SQL query;\n",
    "- execute the query;\n",
    "- use the result to answer the original question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "sql_chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Correct Query from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "### Question Answering using LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, \n",
    "                                    HumanMessagePromptTemplate,\n",
    "                                    ChatPromptTemplate)\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:3b'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"\"\"You are helpful AI assistant who answer user question based on the provided context.\"\"\")\n",
    "\n",
    "prompt = \"\"\"Answer user question based on the provided context ONLY! If you do not know the answer, just say \"I don't know\".\n",
    "            ### Context:\n",
    "            {context}\n",
    "\n",
    "            ### Question:\n",
    "            {question}\n",
    "\n",
    "            ### Answer:\"\"\"\n",
    "\n",
    "prompt = HumanMessagePromptTemplate.from_template(prompt)\n",
    "\n",
    "messages = [system, prompt]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "qna_chain = template | llm | StrOutputParser()\n",
    "\n",
    "def ask_llm(context, question):\n",
    "    return qna_chain.invoke({'context': context, 'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def get_correct_sql_query(input):\n",
    "    context = input['context']\n",
    "    question = input['question']\n",
    "\n",
    "    intruction = \"\"\"\n",
    "        Use above context to fetch the correct SQL query for following question\n",
    "        {}\n",
    "\n",
    "        Do not enclose query in ```sql and do not write preamble and explanation.\n",
    "        You MUST return only single SQL query.\n",
    "    \"\"\".format(question)\n",
    "\n",
    "    response = ask_llm(context=context, question=intruction)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final SQL Query Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "sql_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "final_chain = (\n",
    "    {'context': sql_query, 'question': RunnablePassthrough()}\n",
    "    | get_correct_sql_query\n",
    "    | execute_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3,)]\n"
     ]
    }
   ],
   "source": [
    "question = \"how many transactions are there? You MUST RETURN ONLY MYSQL QUERIES.\"\n",
    "\n",
    "response = final_chain.invoke({'question': question})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
